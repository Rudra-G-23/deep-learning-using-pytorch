{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"![](https://i.pinimg.com/736x/bb/18/e5/bb18e520050d0ef6528339f3c517d23e.jpg)","metadata":{}},{"cell_type":"markdown","source":"# Deep Learning using PyTorch \n\n|No | Topic | My Notebook | Lectures |\n|---| -------- | ----------- | ------------ |\n| 01 | PyTorch for Beginners | [üó∫Ô∏è](https://github.com/Rudra-G-23/AI-Engineering-Resources/tree/main/PyTorch) | [üßë‚Äçüè´](https://youtu.be/QZsguRbcOBM?si=xS9S0YBpN4AtVNiA) |\n| 02 | Tensor in PyTorch | [üìí](https://www.kaggle.com/code/rudraprasadbhuyan/tensors-in-pytorch/) | [üßë‚Äçüè´](https://youtu.be/mDsFsnw3SK4?si=7UXsevk1lyPfcM9B)|\n| 03 |PyTorch Autograd | [üìí](https://www.kaggle.com/code/rudraprasadbhuyan/pytorch-autograd/) | [üßë‚Äçüè´](https://youtu.be/BECZ0UB5AR0?si=fnEYItyybv5nky2y) |\n| 04 |PyTorch Training Pipeline | [üìí](https://www.kaggle.com/code/rudraprasadbhuyan/simple-pytorch-training-pipeline/) | [üßë‚Äçüè´](https://youtu.be/MKxEbbKpL5Q?si=xrUovfzRyXfvmM8E) |\n| 05 | PyTorch NN Module | [üìí](https://www.kaggle.com/code/rudraprasadbhuyan/simple-pytorch-nn-module?scriptVersionId=289809301)[üìí](https://www.kaggle.com/code/rudraprasadbhuyan/pytorch-training-pipeline-using-nn-module?scriptVersionId=289814480) | [üßë‚Äçüè´](https://youtu.be/CAgWNxlmYsc?si=INKJ8VcdQgcYwxAe) |\n|06 |Dataset & DataLoader Class | [üìí](https://www.kaggle.com/code/rudraprasadbhuyan/dataset-and-dataloader-class-in-pytorch)[üìí](https://www.kaggle.com/code/rudraprasadbhuyan/pytorch-training-pipeline-using-dataset-dataloader/) | [üßë‚Äçüè´](https://youtu.be/RH6DeE3bY6I?si=ac6IsukunPNN_dC9) |\n| 07 | ANN using PyTorch | [üìí](https://www.kaggle.com/code/rudraprasadbhuyan/ann-fashion-mnist-pytorch) | [üßë‚Äçüè´](https://youtu.be/6EJaHBJhwDs?si=77w3QVjd2qRTgd3I) |\n| 08 | Trining on GPU | [üìí](https://www.kaggle.com/code/rudraprasadbhuyan/ann-fashion-mnist-pytorch-training-on-gpu/) | [üßë‚Äçüè´](https://youtu.be/CabHrf9eOVs?si=1jETgquzn5gl8Srs) |\n| 09 | Optimizing the Neural Network | [üìí](https://www.kaggle.com/code/rudraprasadbhuyan/ann-fashion-mnist-pytorch-gpu-optimized/) | [üßë‚Äçüè´](https://youtu.be/7smLlJ8oj4o?si=j6N8JIl1_RHwti-2) |\n| 10 | Optuna X PyTorch | [üìí](https://www.kaggle.com/code/rudraprasadbhuyan/ann-fashion-mnist-pytorch-gpu-optimized-optuna/) | [üßë‚Äçüè´](https://youtu.be/Y3s-wBBLj_o?si=sZVcZBWMyTZbSGM2) |\n| 11 | CNN using PyTorch | [üìí](https://www.kaggle.com/code/rudraprasadbhuyan/cnn-using-pytorch-fashion-mnist-gpu/) | [üßë‚Äçüè´](https://youtu.be/hkiBZLRFvO4?si=pbJB9XAWJn2Tu3uM) |\n| 12 | Transfer Learning | [üìí](https://www.kaggle.com/code/rudraprasadbhuyan/transfer-learning-fashion-mnist-pytorch-gpu/) | [üßë‚Äçüè´](https://youtu.be/hkiBZLRFvO4?si=B2SSffNEwdijajhk) |\n| 13 | RNN using PyTorch | [üìí](https://www.kaggle.com/code/rudraprasadbhuyan/rnn-using-pytorch/) | [üßë‚Äçüè´](https://youtu.be/xjzWrPQ66VQ?si=Ngoef4KL9CDM-4lk) |","metadata":{}},{"cell_type":"markdown","source":"- Kaggle Dataset: https://www.kaggle.com/datasets/aadarshvani/100-unique-qa-dataset\n- Drive Dataset Link: https://drive.google.com/file/d/1X4Hcj72NK7J2JYvgjICFj0R1XwUq1w0a/view\n- Repo: https://github.com/Rudra-G-23/deep-learning-using-pytorch","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport torch \nimport torch.nn as nn\nfrom torchinfo import summary\nfrom torch.utils.data import Dataset, DataLoader\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:24.820031Z","iopub.execute_input":"2026-01-04T12:39:24.820547Z","iopub.status.idle":"2026-01-04T12:39:24.825439Z","shell.execute_reply.started":"2026-01-04T12:39:24.820516Z","shell.execute_reply":"2026-01-04T12:39:24.824567Z"}},"outputs":[],"execution_count":275},{"cell_type":"code","source":"path = \"/kaggle/input/100-unique-qa-dataset/100_Unique_QA_Dataset.csv\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:24.854022Z","iopub.execute_input":"2026-01-04T12:39:24.854354Z","iopub.status.idle":"2026-01-04T12:39:24.858747Z","shell.execute_reply.started":"2026-01-04T12:39:24.854329Z","shell.execute_reply":"2026-01-04T12:39:24.857580Z"}},"outputs":[],"execution_count":276},{"cell_type":"code","source":"df = pd.read_csv(path)\ndf.head(3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:24.939054Z","iopub.execute_input":"2026-01-04T12:39:24.939354Z","iopub.status.idle":"2026-01-04T12:39:24.965778Z","shell.execute_reply.started":"2026-01-04T12:39:24.939335Z","shell.execute_reply":"2026-01-04T12:39:24.965010Z"}},"outputs":[{"execution_count":277,"output_type":"execute_result","data":{"text/plain":"                             question      answer\n0      What is the capital of France?       Paris\n1     What is the capital of Germany?      Berlin\n2  Who wrote 'To Kill a Mockingbird'?  Harper-Lee","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>question</th>\n      <th>answer</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>What is the capital of France?</td>\n      <td>Paris</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>What is the capital of Germany?</td>\n      <td>Berlin</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Who wrote 'To Kill a Mockingbird'?</td>\n      <td>Harper-Lee</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":277},{"cell_type":"markdown","source":"# Tokenize","metadata":{}},{"cell_type":"code","source":"def tokenize(text):\n    text = text.lower()\n    text = text.replace(\"?\", \"\")\n    text = text.replace(\"''\", \"\")\n    return text.split()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:24.974228Z","iopub.execute_input":"2026-01-04T12:39:24.974567Z","iopub.status.idle":"2026-01-04T12:39:24.980451Z","shell.execute_reply.started":"2026-01-04T12:39:24.974541Z","shell.execute_reply":"2026-01-04T12:39:24.979484Z"}},"outputs":[],"execution_count":278},{"cell_type":"code","source":"tokenize(\"Who wrote 'To Kill a Mockingbird'?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.035715Z","iopub.execute_input":"2026-01-04T12:39:25.036647Z","iopub.status.idle":"2026-01-04T12:39:25.041685Z","shell.execute_reply.started":"2026-01-04T12:39:25.036616Z","shell.execute_reply":"2026-01-04T12:39:25.040900Z"}},"outputs":[{"execution_count":279,"output_type":"execute_result","data":{"text/plain":"['who', 'wrote', \"'to\", 'kill', 'a', \"mockingbird'\"]"},"metadata":{}}],"execution_count":279},{"cell_type":"markdown","source":"# Vocab","metadata":{}},{"cell_type":"code","source":"vocab = {'<UNK>':0}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.069136Z","iopub.execute_input":"2026-01-04T12:39:25.069447Z","iopub.status.idle":"2026-01-04T12:39:25.073861Z","shell.execute_reply.started":"2026-01-04T12:39:25.069423Z","shell.execute_reply":"2026-01-04T12:39:25.073054Z"}},"outputs":[],"execution_count":280},{"cell_type":"code","source":"def build_vocab(row):\n    tokenized_q = tokenize(row[\"question\"])\n    tokenized_ans = tokenize(row[\"answer\"])\n\n    merged_tokens = tokenized_q + tokenized_ans\n\n    for token in merged_tokens:\n\n        if token not in vocab:\n            vocab[token] = len(vocab)\n            \n    print(merged_tokens)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.114047Z","iopub.execute_input":"2026-01-04T12:39:25.115081Z","iopub.status.idle":"2026-01-04T12:39:25.119787Z","shell.execute_reply.started":"2026-01-04T12:39:25.115051Z","shell.execute_reply":"2026-01-04T12:39:25.118815Z"}},"outputs":[],"execution_count":281},{"cell_type":"code","source":"# now see the vocabulary \nvocab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.168934Z","iopub.execute_input":"2026-01-04T12:39:25.169263Z","iopub.status.idle":"2026-01-04T12:39:25.174684Z","shell.execute_reply.started":"2026-01-04T12:39:25.169238Z","shell.execute_reply":"2026-01-04T12:39:25.173873Z"}},"outputs":[{"execution_count":282,"output_type":"execute_result","data":{"text/plain":"{'<UNK>': 0}"},"metadata":{}}],"execution_count":282},{"cell_type":"code","source":"df.apply(build_vocab, axis=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.244160Z","iopub.execute_input":"2026-01-04T12:39:25.244491Z","iopub.status.idle":"2026-01-04T12:39:25.255260Z","shell.execute_reply.started":"2026-01-04T12:39:25.244468Z","shell.execute_reply":"2026-01-04T12:39:25.254162Z"}},"outputs":[{"name":"stdout","text":"['what', 'is', 'the', 'capital', 'of', 'france', 'paris']\n['what', 'is', 'the', 'capital', 'of', 'germany', 'berlin']\n['who', 'wrote', \"'to\", 'kill', 'a', \"mockingbird'\", 'harper-lee']\n['what', 'is', 'the', 'largest', 'planet', 'in', 'our', 'solar', 'system', 'jupiter']\n['what', 'is', 'the', 'boiling', 'point', 'of', 'water', 'in', 'celsius', '100']\n['who', 'painted', 'the', 'mona', 'lisa', 'leonardo-da-vinci']\n['what', 'is', 'the', 'square', 'root', 'of', '64', '8']\n['what', 'is', 'the', 'chemical', 'symbol', 'for', 'gold', 'au']\n['which', 'year', 'did', 'world', 'war', 'ii', 'end', '1945']\n['what', 'is', 'the', 'longest', 'river', 'in', 'the', 'world', 'nile']\n['what', 'is', 'the', 'capital', 'of', 'japan', 'tokyo']\n['who', 'developed', 'the', 'theory', 'of', 'relativity', 'albert-einstein']\n['what', 'is', 'the', 'freezing', 'point', 'of', 'water', 'in', 'fahrenheit', '32']\n['which', 'planet', 'is', 'known', 'as', 'the', 'red', 'planet', 'mars']\n['who', 'is', 'the', 'author', 'of', \"'1984'\", 'george-orwell']\n['what', 'is', 'the', 'currency', 'of', 'the', 'united', 'kingdom', 'pound']\n['what', 'is', 'the', 'capital', 'of', 'india', 'delhi']\n['who', 'discovered', 'gravity', 'newton']\n['how', 'many', 'continents', 'are', 'there', 'on', 'earth', '7']\n['which', 'gas', 'do', 'plants', 'use', 'for', 'photosynthesis', 'co2']\n['what', 'is', 'the', 'smallest', 'prime', 'number', '2']\n['who', 'invented', 'the', 'telephone', 'alexander-graham-bell']\n['what', 'is', 'the', 'capital', 'of', 'australia', 'canberra']\n['which', 'ocean', 'is', 'the', 'largest', 'pacific-ocean']\n['what', 'is', 'the', 'speed', 'of', 'light', 'in', 'vacuum', '299,792,458m/s']\n['which', 'language', 'is', 'spoken', 'in', 'brazil', 'portuguese']\n['who', 'discovered', 'penicillin', 'alexander-fleming']\n['what', 'is', 'the', 'capital', 'of', 'canada', 'ottawa']\n['what', 'is', 'the', 'largest', 'mammal', 'on', 'earth', 'whale']\n['which', 'element', 'has', 'the', 'atomic', 'number', '1', 'hydrogen']\n['what', 'is', 'the', 'tallest', 'mountain', 'in', 'the', 'world', 'everest']\n['which', 'city', 'is', 'known', 'as', 'the', 'big', 'apple', 'newyork']\n['how', 'many', 'planets', 'are', 'in', 'the', 'solar', 'system', '8']\n['who', 'painted', \"'starry\", \"night'\", 'vangogh']\n['what', 'is', 'the', 'chemical', 'formula', 'of', 'water', 'h2o']\n['what', 'is', 'the', 'capital', 'of', 'italy', 'rome']\n['which', 'country', 'is', 'famous', 'for', 'sushi', 'japan']\n['who', 'was', 'the', 'first', 'person', 'to', 'step', 'on', 'the', 'moon', 'armstrong']\n['what', 'is', 'the', 'main', 'ingredient', 'in', 'guacamole', 'avocado']\n['how', 'many', 'sides', 'does', 'a', 'hexagon', 'have', '6']\n['what', 'is', 'the', 'currency', 'of', 'china', 'yuan']\n['who', 'wrote', \"'pride\", 'and', \"prejudice'\", 'jane-austen']\n['what', 'is', 'the', 'chemical', 'symbol', 'for', 'iron', 'fe']\n['what', 'is', 'the', 'hardest', 'natural', 'substance', 'on', 'earth', 'diamond']\n['which', 'continent', 'is', 'the', 'largest', 'by', 'area', 'asia']\n['who', 'was', 'the', 'first', 'president', 'of', 'the', 'united', 'states', 'george-washington']\n['which', 'bird', 'is', 'known', 'for', 'its', 'ability', 'to', 'mimic', 'sounds', 'parrot']\n['what', 'is', 'the', 'longest-running', 'animated', 'tv', 'show', 'simpsons']\n['what', 'is', 'the', 'smallest', 'country', 'in', 'the', 'world', 'vaticancity']\n['which', 'planet', 'has', 'the', 'most', 'moons', 'saturn']\n['who', 'wrote', \"'romeo\", 'and', \"juliet'\", 'shakespeare']\n['what', 'is', 'the', 'main', 'gas', 'in', \"earth's\", 'atmosphere', 'nitrogen']\n['how', 'many', 'bones', 'are', 'in', 'the', 'adult', 'human', 'body', '206']\n['which', 'metal', 'is', 'a', 'liquid', 'at', 'room', 'temperature', 'mercury']\n['what', 'is', 'the', 'capital', 'of', 'russia', 'moscow']\n['who', 'discovered', 'electricity', 'benjamin-franklin']\n['which', 'is', 'the', 'second-largest', 'country', 'by', 'land', 'area', 'canada']\n['what', 'is', 'the', 'color', 'of', 'a', 'ripe', 'banana', 'yellow']\n['which', 'month', 'has', '28', 'days', 'in', 'a', 'common', 'year', 'february']\n['what', 'is', 'the', 'study', 'of', 'living', 'organisms', 'called', 'biology']\n['which', 'country', 'is', 'home', 'to', 'the', 'great', 'wall', 'china']\n['what', 'do', 'bees', 'collect', 'from', 'flowers', 'nectar']\n['what', 'is', 'the', 'opposite', 'of', \"'day'\", 'night']\n['what', 'is', 'the', 'capital', 'of', 'south', 'korea', 'seoul']\n['who', 'invented', 'the', 'light', 'bulb', 'edison']\n['which', 'gas', 'do', 'humans', 'breathe', 'in', 'for', 'survival', 'oxygen']\n['what', 'is', 'the', 'square', 'root', 'of', '144', '12']\n['which', 'country', 'has', 'the', 'pyramids', 'of', 'giza', 'egypt']\n['which', 'sea', 'creature', 'has', 'eight', 'arms', 'octopus']\n['which', 'holiday', 'is', 'celebrated', 'on', 'december', '25', 'christmas']\n['what', 'is', 'the', 'currency', 'of', 'japan', 'yen']\n['how', 'many', 'legs', 'does', 'a', 'spider', 'have', '8']\n['which', 'sport', 'uses', 'a', 'net,', 'ball,', 'and', 'hoop', 'basketball']\n['which', 'country', 'is', 'famous', 'for', 'its', 'kangaroos', 'australia']\n['who', 'was', 'the', 'first', 'female', 'prime', 'minister', 'of', 'the', 'uk', 'margaretthatcher']\n['which', 'is', 'the', 'fastest', 'land', 'animal', 'cheetah']\n['what', 'is', 'the', 'first', 'element', 'on', 'the', 'periodic', 'table', 'hydrogen']\n['what', 'is', 'the', 'capital', 'of', 'spain', 'madrid']\n['which', 'planet', 'is', 'the', 'closest', 'to', 'the', 'sun', 'mercury']\n['who', 'is', 'known', 'as', 'the', 'father', 'of', 'computers', 'charlesbabbage']\n['what', 'is', 'the', 'capital', 'of', 'mexico', 'mexicocity']\n['how', 'many', 'colors', 'are', 'in', 'a', 'rainbow', '7']\n['which', 'musical', 'instrument', 'has', 'black', 'and', 'white', 'keys', 'piano']\n['who', 'discovered', 'the', 'americas', 'in', '1492', 'christophercolumbus']\n['which', 'disney', 'character', 'has', 'a', 'long', 'nose', 'and', 'grows', 'it', 'when', 'lying', 'pinocchio']\n['who', 'directed', 'the', 'movie', \"'titanic'\", 'jamescameron']\n['which', 'superhero', 'is', 'also', 'known', 'as', 'the', 'dark', 'knight', 'batman']\n['what', 'is', 'the', 'capital', 'of', 'brazil', 'brasilia']\n['which', 'fruit', 'is', 'known', 'as', 'the', 'king', 'of', 'fruits', 'mango']\n['which', 'country', 'is', 'known', 'for', 'the', 'eiffel', 'tower', 'france']\n","output_type":"stream"},{"execution_count":283,"output_type":"execute_result","data":{"text/plain":"0     None\n1     None\n2     None\n3     None\n4     None\n      ... \n85    None\n86    None\n87    None\n88    None\n89    None\nLength: 90, dtype: object"},"metadata":{}}],"execution_count":283},{"cell_type":"markdown","source":"# Word -> Numerical Inices ","metadata":{}},{"cell_type":"code","source":"def text_to_indices(text, vocab):\n\n    indexed_text = []\n\n    for token in tokenize(text):\n\n        if token in vocab:\n            indexed_text.append(vocab[token])\n        else:\n            indexed_text.append(vocab['<UNK>'])\n    \n    return indexed_text","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.299046Z","iopub.execute_input":"2026-01-04T12:39:25.299383Z","iopub.status.idle":"2026-01-04T12:39:25.304495Z","shell.execute_reply.started":"2026-01-04T12:39:25.299358Z","shell.execute_reply":"2026-01-04T12:39:25.303505Z"}},"outputs":[],"execution_count":284},{"cell_type":"code","source":"# see example\ntext_to_indices(\"Who is Rudra?\", vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.324195Z","iopub.execute_input":"2026-01-04T12:39:25.324806Z","iopub.status.idle":"2026-01-04T12:39:25.329941Z","shell.execute_reply.started":"2026-01-04T12:39:25.324780Z","shell.execute_reply":"2026-01-04T12:39:25.329082Z"}},"outputs":[{"execution_count":285,"output_type":"execute_result","data":{"text/plain":"[10, 2, 0]"},"metadata":{}}],"execution_count":285},{"cell_type":"code","source":"# Check the vocab\nfor t in [\"who\", \"is\", \"rudra\"]:\n    print(vocab.get(t))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.414616Z","iopub.execute_input":"2026-01-04T12:39:25.414924Z","iopub.status.idle":"2026-01-04T12:39:25.419733Z","shell.execute_reply.started":"2026-01-04T12:39:25.414903Z","shell.execute_reply":"2026-01-04T12:39:25.418925Z"}},"outputs":[{"name":"stdout","text":"10\n2\nNone\n","output_type":"stream"}],"execution_count":286},{"cell_type":"markdown","source":"# Custom Dataset Class","metadata":{}},{"cell_type":"code","source":"class QADataset(Dataset):\n\n    def __init__(self, df, vocab):\n        self.df = df\n        self.vocab = vocab\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, idx):\n        numeric_q = text_to_indices(self.df.iloc[idx][\"question\"], self.vocab)\n        numeric_ans = text_to_indices(self.df.iloc[idx][\"answer\"], self.vocab)\n\n        return torch.tensor(numeric_q), torch.tensor(numeric_ans)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.445531Z","iopub.execute_input":"2026-01-04T12:39:25.446154Z","iopub.status.idle":"2026-01-04T12:39:25.452086Z","shell.execute_reply.started":"2026-01-04T12:39:25.446119Z","shell.execute_reply":"2026-01-04T12:39:25.451096Z"}},"outputs":[],"execution_count":287},{"cell_type":"code","source":"# instance\ndataset = QADataset(df, vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.489146Z","iopub.execute_input":"2026-01-04T12:39:25.490009Z","iopub.status.idle":"2026-01-04T12:39:25.494063Z","shell.execute_reply.started":"2026-01-04T12:39:25.489974Z","shell.execute_reply":"2026-01-04T12:39:25.492947Z"}},"outputs":[],"execution_count":288},{"cell_type":"code","source":"# check we can load data properly with our requirement \ndataset[10]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.551085Z","iopub.execute_input":"2026-01-04T12:39:25.551484Z","iopub.status.idle":"2026-01-04T12:39:25.558763Z","shell.execute_reply.started":"2026-01-04T12:39:25.551457Z","shell.execute_reply":"2026-01-04T12:39:25.557821Z"}},"outputs":[{"execution_count":289,"output_type":"execute_result","data":{"text/plain":"(tensor([ 1,  2,  3,  4,  5, 53]), tensor([54]))"},"metadata":{}}],"execution_count":289},{"cell_type":"markdown","source":"# Data Loader Class","metadata":{}},{"cell_type":"code","source":"dataloader = DataLoader(dataset, batch_size=1, shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.614299Z","iopub.execute_input":"2026-01-04T12:39:25.614603Z","iopub.status.idle":"2026-01-04T12:39:25.619559Z","shell.execute_reply.started":"2026-01-04T12:39:25.614579Z","shell.execute_reply":"2026-01-04T12:39:25.618692Z"}},"outputs":[],"execution_count":290},{"cell_type":"code","source":"dataloader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.669847Z","iopub.execute_input":"2026-01-04T12:39:25.670180Z","iopub.status.idle":"2026-01-04T12:39:25.675862Z","shell.execute_reply.started":"2026-01-04T12:39:25.670154Z","shell.execute_reply":"2026-01-04T12:39:25.674986Z"}},"outputs":[{"execution_count":291,"output_type":"execute_result","data":{"text/plain":"<torch.utils.data.dataloader.DataLoader at 0x7b7c4a691e10>"},"metadata":{}}],"execution_count":291},{"cell_type":"code","source":"for q, ans in dataloader:\n    print(q, ans)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.731847Z","iopub.execute_input":"2026-01-04T12:39:25.732167Z","iopub.status.idle":"2026-01-04T12:39:25.784203Z","shell.execute_reply.started":"2026-01-04T12:39:25.732137Z","shell.execute_reply":"2026-01-04T12:39:25.783236Z"}},"outputs":[{"name":"stdout","text":"tensor([[  1,   2,   3, 147, 148,  19, 149]]) tensor([[150]])\ntensor([[  1,   2,   3, 164, 165, 166,  83,  84]]) tensor([[167]])\ntensor([[10,  2,  3, 66,  5, 67]]) tensor([[68]])\ntensor([[ 42, 117, 118,   3, 119,  94, 120]]) tensor([[121]])\ntensor([[ 42, 137,   2, 227, 143,   3, 228, 229]]) tensor([[156]])\ntensor([[10, 11, 12, 13, 14, 15]]) tensor([[16]])\ntensor([[ 42, 168,   2,   3,  17, 169, 170]]) tensor([[171]])\ntensor([[10, 96,  3, 97]]) tensor([[98]])\ntensor([[ 10, 140,   3, 141, 272,  93, 273,   5,   3, 274]]) tensor([[275]])\ntensor([[ 42, 314,   2, 315,  62,  63,   3, 316, 317]]) tensor([[318]])\ntensor([[ 1,  2,  3, 69,  5,  3, 70, 71]]) tensor([[72]])\ntensor([[  1,   2,   3,  37,  38,  39, 162]]) tensor([[163]])\ntensor([[  1,  87, 230, 231, 232, 233]]) tensor([[234]])\ntensor([[ 42, 217, 118, 218, 219,  19,  14, 220,  43]]) tensor([[221]])\ntensor([[42, 18,  2, 62, 63,  3, 64, 18]]) tensor([[65]])\ntensor([[ 42, 175,   2,  62,  39, 176, 177, 143, 178, 179]]) tensor([[180]])\ntensor([[1, 2, 3, 4, 5, 6]]) tensor([[7]])\ntensor([[1, 2, 3, 4, 5, 8]]) tensor([[9]])\ntensor([[  1,   2,   3, 222,   5, 223, 224, 225]]) tensor([[226]])\ntensor([[  1,   2,   3,   4,   5, 113]]) tensor([[114]])\ntensor([[ 1,  2,  3, 92, 93, 94]]) tensor([[95]])\ntensor([[42, 86, 87, 88, 89, 39, 90]]) tensor([[91]])\ntensor([[  1,   2,   3,   4,   5, 109]]) tensor([[319]])\ntensor([[ 1,  2,  3,  4,  5, 53]]) tensor([[54]])\ntensor([[ 78,  79, 196,  81,  19,   3, 197, 198, 199]]) tensor([[200]])\ntensor([[ 1,  2,  3, 33, 34,  5, 35]]) tensor([[36]])\ntensor([[78, 79, 80, 81, 82, 83, 84]]) tensor([[85]])\ntensor([[ 42,   2,   3, 211, 137, 169, 212, 170]]) tensor([[113]])\ntensor([[ 42,  86,  87, 243, 244,  19,  39, 245]]) tensor([[246]])\ntensor([[  1,   2,   3, 213,   5,  14, 214, 215]]) tensor([[216]])\ntensor([[ 42, 257,   2, 258,  83, 259, 260]]) tensor([[261]])\ntensor([[  1,   2,   3,  33,  34,   5, 247]]) tensor([[248]])\ntensor([[ 42, 137,   2, 138,  39, 176, 271]]) tensor([[99]])\ntensor([[ 1,  2,  3, 37, 38, 39, 40]]) tensor([[41]])\ntensor([[10, 75, 76]]) tensor([[77]])\ntensor([[ 78,  79, 151, 152,  14, 153, 154]]) tensor([[155]])\ntensor([[ 42, 265, 266,  14, 267, 268, 159, 269]]) tensor([[270]])\ntensor([[42, 43, 44, 45, 46, 47, 48]]) tensor([[49]])\ntensor([[ 42, 101,   2,   3,  17]]) tensor([[102]])\ntensor([[ 10,  11, 158, 159, 160]]) tensor([[161]])\ntensor([[ 1,  2,  3, 69,  5, 53]]) tensor([[262]])\ntensor([[  1,   2,   3,  17, 115,  83,  84]]) tensor([[116]])\ntensor([[10, 55,  3, 56,  5, 57]]) tensor([[58]])\ntensor([[ 1,  2,  3, 59, 25,  5, 26, 19, 60]]) tensor([[61]])\ntensor([[  1,   2,   3,  92, 137,  19,   3,  45]]) tensor([[186]])\ntensor([[  1,   2,   3, 147,  86,  19, 193, 194]]) tensor([[195]])\ntensor([[ 10,  96,   3, 104, 241]]) tensor([[242]])\ntensor([[  1,   2,   3,  69,   5, 156]]) tensor([[157]])\ntensor([[10, 29,  3, 30, 31]]) tensor([[32]])\ntensor([[ 42, 125,   2,  62,  63,   3, 126, 127]]) tensor([[128]])\ntensor([[ 10, 140,   3, 141, 142, 143, 144,  83,   3, 145]]) tensor([[146]])\ntensor([[  1,   2,   3,   4,   5, 288]]) tensor([[289]])\ntensor([[ 42, 137,   2, 138,  39, 139]]) tensor([[53]])\ntensor([[ 78,  79, 290,  81,  19,  14, 291]]) tensor([[85]])\ntensor([[  1,   2,   3, 122, 123,  19,   3,  45]]) tensor([[124]])\ntensor([[ 10,  75, 209]]) tensor([[210]])\ntensor([[ 42, 107,   2, 108,  19, 109]]) tensor([[110]])\ntensor([[ 10,  11, 190, 159, 191]]) tensor([[192]])\ntensor([[ 1,  2,  3,  4,  5, 73]]) tensor([[74]])\ntensor([[ 78,  79, 129,  81,  19,   3,  21,  22]]) tensor([[36]])\ntensor([[  1,   2,   3, 141, 117,  83,   3, 279, 280]]) tensor([[121]])\ntensor([[ 10, 310,   3, 311, 312]]) tensor([[313]])\ntensor([[ 42, 292, 293, 118, 294, 159, 295, 296]]) tensor([[297]])\ntensor([[ 10,  29, 130, 131]]) tensor([[132]])\ntensor([[ 1,  2,  3,  4,  5, 99]]) tensor([[100]])\ntensor([[ 42, 320,   2,  62,  63,   3, 321,   5, 322]]) tensor([[323]])\ntensor([[  1,   2,   3, 181, 182, 183, 184]]) tensor([[185]])\ntensor([[  1,   2,   3, 103,   5, 104,  19, 105]]) tensor([[106]])\ntensor([[ 1,  2,  3, 24, 25,  5, 26, 19, 27]]) tensor([[28]])\ntensor([[ 1,  2,  3, 50, 51, 19,  3, 45]]) tensor([[52]])\ntensor([[ 42,  18,   2,   3, 283, 143,   3, 284]]) tensor([[206]])\ntensor([[ 1,  2,  3, 17, 18, 19, 20, 21, 22]]) tensor([[23]])\ntensor([[ 42, 252, 253, 118, 254, 255]]) tensor([[256]])\ntensor([[ 42, 301, 302, 118,  14, 303, 304, 159, 305, 306, 307, 308]]) tensor([[309]])\ntensor([[  1,   2,   3,   4,   5, 135]]) tensor([[136]])\ntensor([[ 42, 201,   2,  14, 202, 203, 204, 205]]) tensor([[206]])\ntensor([[ 42,  18, 118,   3, 187, 188]]) tensor([[189]])\ntensor([[ 42, 137, 118,   3, 249,   5, 250]]) tensor([[251]])\ntensor([[ 42, 137,   2,  62,  39,   3, 324, 325]]) tensor([[6]])\ntensor([[ 42,   2,   3, 276, 212, 277]]) tensor([[278]])\ntensor([[ 78,  79, 263, 152,  14, 264, 154]]) tensor([[36]])\ntensor([[ 10,  75,   3, 298,  19, 299]]) tensor([[300]])\ntensor([[  1,   2,   3,  37, 133,   5,  26]]) tensor([[134]])\ntensor([[ 10,  75, 111]]) tensor([[112]])\ntensor([[  1,   2,   3,   4,   5, 207]]) tensor([[208]])\ntensor([[ 10, 140,   3, 141, 172,   5,   3,  70, 173]]) tensor([[174]])\ntensor([[ 10,   2,  62,  63,   3, 285,   5, 286]]) tensor([[287]])\ntensor([[  1,   2,   3,   4,   5, 281]]) tensor([[282]])\ntensor([[  1,   2,   3, 235,   5, 236]]) tensor([[237]])\ntensor([[  1,   2,   3,   4,   5, 238, 239]]) tensor([[240]])\n","output_type":"stream"}],"execution_count":292},{"cell_type":"markdown","source":"# Simple NN class","metadata":{}},{"cell_type":"markdown","source":"Neural Network \n\n- One input layer (50 neurons)\n- one hidden layer (64 neurons\n- one output layer (324 neurons), which is vocab_size=324\n- 50-dimensional embedding ","metadata":{}},{"cell_type":"code","source":"class SimpleRNN(nn.Module):\n\n    def __init__(self, vocab_size):\n\n        super().__init__()\n        self.embedding = nn.Embedding(vocab_size, embedding_dim=50)\n        self.rnn = nn.RNN(50, 64, batch_first=True)\n        self.fc = nn.Linear(64, vocab_size)\n\n    def forward(self, question):\n        embeded_q = self.embedding(question)\n        hidden, final = self.rnn(embeded_q)\n        out = self.fc(final.squeeze(0))\n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.785785Z","iopub.execute_input":"2026-01-04T12:39:25.786227Z","iopub.status.idle":"2026-01-04T12:39:25.793313Z","shell.execute_reply.started":"2026-01-04T12:39:25.786195Z","shell.execute_reply":"2026-01-04T12:39:25.792164Z"}},"outputs":[],"execution_count":293},{"cell_type":"markdown","source":"# Check & RNN fundamentals ","metadata":{}},{"cell_type":"markdown","source":"## Embedding (Input Layer)","metadata":{}},{"cell_type":"code","source":"# first q&a fetch\ndataset[45]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.814058Z","iopub.execute_input":"2026-01-04T12:39:25.814383Z","iopub.status.idle":"2026-01-04T12:39:25.821477Z","shell.execute_reply.started":"2026-01-04T12:39:25.814359Z","shell.execute_reply":"2026-01-04T12:39:25.820649Z"}},"outputs":[{"execution_count":294,"output_type":"execute_result","data":{"text/plain":"(tensor([ 10, 140,   3, 141, 172,   5,   3,  70, 173]), tensor([174]))"},"metadata":{}}],"execution_count":294},{"cell_type":"code","source":"x = nn.Embedding(324, embedding_dim=50)\nx","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.853978Z","iopub.execute_input":"2026-01-04T12:39:25.854321Z","iopub.status.idle":"2026-01-04T12:39:25.861334Z","shell.execute_reply.started":"2026-01-04T12:39:25.854297Z","shell.execute_reply":"2026-01-04T12:39:25.860335Z"}},"outputs":[{"execution_count":295,"output_type":"execute_result","data":{"text/plain":"Embedding(324, 50)"},"metadata":{}}],"execution_count":295},{"cell_type":"code","source":"# only question sent to embedding\na = x(dataset[45][0]) \na","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.899791Z","iopub.execute_input":"2026-01-04T12:39:25.900088Z","iopub.status.idle":"2026-01-04T12:39:25.911337Z","shell.execute_reply.started":"2026-01-04T12:39:25.900066Z","shell.execute_reply":"2026-01-04T12:39:25.910557Z"}},"outputs":[{"execution_count":296,"output_type":"execute_result","data":{"text/plain":"tensor([[-2.0004e+00,  7.5953e-02,  1.2621e+00, -3.2058e-01, -1.2299e+00,\n         -5.1092e-01,  9.5349e-02, -2.6320e+00, -2.7914e-01,  1.9502e-01,\n          3.0940e-01,  1.7999e+00, -3.9919e-01, -1.9983e-02, -7.4350e-01,\n         -2.2623e-01,  4.2789e-01, -2.9628e-01, -6.9202e-01, -2.3869e-02,\n          1.6062e+00, -2.5377e-01,  6.1512e-01,  8.8098e-01, -8.7469e-01,\n         -1.4060e+00,  9.2733e-01, -6.0122e-01,  8.7368e-01,  2.5087e-01,\n          9.8199e-01,  9.0094e-02, -5.2529e-01,  1.3630e+00,  2.1529e-01,\n          6.2076e-02,  6.7904e-01,  1.0018e-01,  4.8726e-01,  3.3160e-01,\n          4.4323e-01, -4.4627e-01, -2.5194e-01, -1.2440e+00,  3.2140e-01,\n          7.1988e-01, -4.1474e-01,  2.0010e+00,  4.5588e-01, -1.8904e+00],\n        [-5.5239e-01,  1.2640e+00, -1.8220e-01,  5.1918e-03, -4.4131e-01,\n          2.8270e-01, -1.5224e+00,  3.7523e-01,  1.1971e+00, -2.1619e+00,\n          2.0662e-01,  9.1449e-01, -7.5858e-01, -1.2834e+00,  1.1329e+00,\n         -1.7198e-01,  4.7598e-01,  1.5089e+00, -1.6377e+00,  7.7098e-01,\n         -6.1813e-01,  1.3649e+00, -1.5393e+00,  5.3238e-01,  7.7811e-02,\n         -5.9319e-01,  6.2655e-01,  1.7531e-01,  1.7989e+00, -6.2788e-01,\n          8.1952e-01, -7.1888e-01,  5.3135e-01,  1.1746e+00,  2.3903e+00,\n         -1.0115e+00,  5.5787e-01, -1.2722e+00,  1.4668e+00, -5.3445e-01,\n         -9.8491e-01,  6.1605e-01, -4.7260e-01, -3.7096e-01,  2.5392e-01,\n          5.8262e-01,  3.5364e-02, -1.4595e+00,  9.0447e-01,  1.0561e+00],\n        [-1.3885e-01, -1.7993e+00,  1.0646e+00, -8.4355e-01, -6.0208e-01,\n         -5.5293e-01, -1.0546e+00,  9.1055e-01,  4.8162e-01, -1.1540e+00,\n         -6.6759e-02,  4.6208e-01, -1.2619e+00, -1.3438e+00,  1.2141e-01,\n         -1.0931e+00,  2.2348e-01, -5.8285e-01,  9.3556e-02, -9.8211e-01,\n         -5.5100e-01, -1.0069e-01, -4.8606e-01, -8.4111e-01,  4.9352e-01,\n          1.1417e+00, -4.1766e-01, -2.1274e-01, -1.0496e+00, -1.6733e-02,\n          2.1338e+00,  9.0052e-01,  1.7209e+00, -7.7935e-01, -7.4867e-01,\n          1.1087e+00, -1.1590e+00, -1.0542e+00,  9.4954e-01,  9.1021e-01,\n         -1.3903e+00, -2.4384e-01,  7.0677e-01,  1.1077e+00, -4.8591e-03,\n          4.6583e-01,  4.5111e-01, -6.1381e-01, -4.0372e-01, -1.8798e-02],\n        [ 1.2892e+00, -7.3931e-01, -1.4212e+00,  6.3671e-01,  5.4264e-01,\n         -5.4516e-01,  5.3654e-01,  2.0061e-01,  3.7241e-01, -4.2279e-01,\n         -1.2624e+00,  1.3488e+00,  1.3137e+00,  9.8413e-01,  1.6933e-03,\n         -1.3015e+00,  5.8606e-01,  1.4402e+00,  2.2016e+00, -1.7294e-02,\n         -2.1023e-01,  7.0325e-01,  3.1608e-01, -5.2034e-01,  3.8115e-01,\n         -1.3740e+00, -8.0282e-01,  1.8239e+00,  1.8566e-01, -2.5353e-01,\n          1.1110e+00,  1.0527e-01,  1.9326e+00, -1.0149e+00,  1.1404e+00,\n         -2.8466e-01,  7.9941e-01,  3.0448e+00, -2.3599e-01,  4.6936e-02,\n         -1.9342e-01,  1.1301e+00,  2.6555e-01,  5.6011e-01, -4.6241e-02,\n          8.7619e-01, -6.2693e-01,  7.2332e-01,  1.1375e+00,  1.4957e+00],\n        [ 3.5403e-02, -4.1261e-01, -6.5905e-01,  5.9700e-01, -6.5567e-01,\n         -1.5718e+00, -9.7136e-01, -2.4597e+00, -9.9545e-01, -1.7369e+00,\n         -5.8802e-01,  1.0744e+00,  4.0689e-01,  1.0631e+00, -9.8902e-01,\n          9.7816e-01,  1.1315e-01, -5.0055e-03,  5.3421e-01, -4.1657e-01,\n         -6.5240e-01, -1.1245e+00, -4.7733e-01, -1.4160e+00,  2.8495e-02,\n         -1.8273e+00,  1.0596e-01, -2.6220e-01,  1.0437e+00,  1.4130e+00,\n          1.4505e+00, -1.6659e+00,  1.2109e+00,  1.2239e-01,  8.2305e-01,\n          1.2968e+00, -1.1965e+00,  1.2697e-02,  4.9664e-01,  7.7857e-01,\n          1.1868e+00,  1.3215e+00,  1.3972e+00,  5.8338e-01, -4.6445e-02,\n         -4.7260e-01,  1.0450e+00,  1.3820e-01, -1.3983e+00,  2.5652e-01],\n        [-7.7699e-01, -7.4107e-01, -1.7689e-01, -9.5976e-01, -1.5928e+00,\n         -1.0415e+00,  2.2625e+00,  1.3239e+00, -2.5962e-02,  7.0822e-01,\n          2.8829e-01, -4.0517e-01, -2.3864e-01,  2.1605e+00,  4.3196e-01,\n         -7.9061e-01, -1.8245e+00,  2.3746e-02, -4.9822e-01,  1.6257e+00,\n          8.9655e-01,  4.9559e-01,  1.1359e-01,  5.3639e-03,  1.3053e+00,\n          1.8832e-01,  1.2471e+00, -7.9175e-01, -1.3297e+00, -5.1906e-01,\n         -1.1712e+00, -6.5525e-01, -1.2434e+00, -1.0350e+00,  5.1004e-01,\n          1.6783e-01,  4.5485e-01, -2.7096e-01,  8.3607e-01,  8.7902e-01,\n         -5.5349e-01,  5.9748e-01, -3.6628e-01,  1.1363e+00, -7.9594e-01,\n         -4.3401e-01, -1.1618e+00, -1.7777e-01,  2.5881e+00,  9.7546e-01],\n        [-1.3885e-01, -1.7993e+00,  1.0646e+00, -8.4355e-01, -6.0208e-01,\n         -5.5293e-01, -1.0546e+00,  9.1055e-01,  4.8162e-01, -1.1540e+00,\n         -6.6759e-02,  4.6208e-01, -1.2619e+00, -1.3438e+00,  1.2141e-01,\n         -1.0931e+00,  2.2348e-01, -5.8285e-01,  9.3556e-02, -9.8211e-01,\n         -5.5100e-01, -1.0069e-01, -4.8606e-01, -8.4111e-01,  4.9352e-01,\n          1.1417e+00, -4.1766e-01, -2.1274e-01, -1.0496e+00, -1.6733e-02,\n          2.1338e+00,  9.0052e-01,  1.7209e+00, -7.7935e-01, -7.4867e-01,\n          1.1087e+00, -1.1590e+00, -1.0542e+00,  9.4954e-01,  9.1021e-01,\n         -1.3903e+00, -2.4384e-01,  7.0677e-01,  1.1077e+00, -4.8591e-03,\n          4.6583e-01,  4.5111e-01, -6.1381e-01, -4.0372e-01, -1.8798e-02],\n        [ 5.4580e-02,  2.6583e+00, -1.0323e+00,  1.4171e+00, -4.7202e-01,\n          8.7798e-01,  3.0553e-01, -1.4722e+00,  3.7979e-01,  4.2695e-01,\n          2.3379e-01, -4.3746e-01, -1.7339e+00,  8.1154e-01,  9.3665e-01,\n          8.1162e-01, -1.1448e+00,  1.1968e+00, -3.4713e-01,  7.2083e-01,\n          4.3156e-01, -5.5725e-01, -9.4840e-01, -1.5069e-02, -4.5550e-01,\n         -1.5317e+00,  1.2448e+00, -1.8850e-01, -6.6684e-02, -4.1789e-01,\n          8.8149e-01, -7.0858e-01, -2.7238e-02, -5.0258e-01,  8.8124e-01,\n         -3.2085e-01,  6.8987e-01, -4.1637e-01, -1.1709e+00, -1.7301e-01,\n         -5.7056e-01,  2.9252e-01, -1.0307e+00,  6.4242e-01,  4.9363e-02,\n         -1.5259e+00, -1.0131e+00, -1.4101e-01, -1.6457e+00, -3.2835e-01],\n        [-8.4301e-01,  1.4540e+00,  4.1778e-01, -6.9997e-02, -1.8453e-01,\n          1.0085e+00,  3.5177e-01, -1.3792e+00,  1.3248e-01,  3.2880e-01,\n         -6.4173e-01, -5.8269e-01,  1.2762e+00, -2.0565e-01,  1.1159e+00,\n         -1.3761e+00, -1.4128e+00, -2.0510e-01, -1.8434e-01,  5.4721e-01,\n          1.6404e+00,  8.2753e-02, -9.3275e-01, -1.9779e-01, -8.5860e-01,\n         -1.5944e+00,  6.5950e-01, -1.2110e+00,  1.0203e+00,  4.0145e-01,\n         -1.0985e+00,  2.5188e-02, -1.8662e+00,  2.3203e-02, -2.2119e-01,\n          7.2218e-02,  2.2605e+00, -9.8263e-02, -2.7501e-01, -2.6065e+00,\n          1.6557e-01,  4.5607e-01, -1.3131e+00, -7.2506e-01, -1.2782e+00,\n          1.1413e+00, -5.2585e-01, -1.0661e-01, -3.9789e-01,  1.1965e+00]],\n       grad_fn=<EmbeddingBackward0>)"},"metadata":{}}],"execution_count":296},{"cell_type":"code","source":"print(a.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.949020Z","iopub.execute_input":"2026-01-04T12:39:25.949344Z","iopub.status.idle":"2026-01-04T12:39:25.954472Z","shell.execute_reply.started":"2026-01-04T12:39:25.949323Z","shell.execute_reply":"2026-01-04T12:39:25.953439Z"}},"outputs":[{"name":"stdout","text":"torch.Size([9, 50])\n","output_type":"stream"}],"execution_count":297},{"cell_type":"markdown","source":"## RNN example (Hidden Layer)","metadata":{}},{"cell_type":"code","source":"# now we see the RNN \n# What RNN does with this embedding \n# 50 dim and 64 outputs\ny = nn.RNN(50, 64)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:25.984279Z","iopub.execute_input":"2026-01-04T12:39:25.984918Z","iopub.status.idle":"2026-01-04T12:39:25.989906Z","shell.execute_reply.started":"2026-01-04T12:39:25.984888Z","shell.execute_reply":"2026-01-04T12:39:25.988892Z"}},"outputs":[],"execution_count":298},{"cell_type":"markdown","source":"![](https://i.pinimg.com/736x/c6/14/db/c614dbf3fc040cc1f2a7161f4b224228.jpg)","metadata":{}},{"cell_type":"code","source":"# two tupple\ny(a)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:26.043897Z","iopub.execute_input":"2026-01-04T12:39:26.044543Z","iopub.status.idle":"2026-01-04T12:39:26.057120Z","shell.execute_reply.started":"2026-01-04T12:39:26.044516Z","shell.execute_reply":"2026-01-04T12:39:26.056127Z"}},"outputs":[{"execution_count":299,"output_type":"execute_result","data":{"text/plain":"(tensor([[-0.2486, -0.4983, -0.1773, -0.1265,  0.1133,  0.6968,  0.7148, -0.1298,\n          -0.1708, -0.4045,  0.4692, -0.1653, -0.3188,  0.5821,  0.0809,  0.0675,\n          -0.2989,  0.1629,  0.2005, -0.1664,  0.7893, -0.1634, -0.3210, -0.2256,\n          -0.8517,  0.1115, -0.1994, -0.1522, -0.5058,  0.6796,  0.2720, -0.2281,\n          -0.6166,  0.1463, -0.5640,  0.5867, -0.0148,  0.1488,  0.4264,  0.0836,\n          -0.1851,  0.2303, -0.1853,  0.0345, -0.5174, -0.1076,  0.0730,  0.2008,\n           0.3194, -0.2464,  0.1246, -0.1831,  0.4843,  0.1261,  0.3453, -0.3822,\n          -0.3025,  0.0804, -0.0257, -0.2708,  0.1592,  0.2884,  0.1749, -0.2183],\n         [-0.3591,  0.4443,  0.3611, -0.4099, -0.0385, -0.1709, -0.0205, -0.8223,\n          -0.7038, -0.8054,  0.6134, -0.4221,  0.0130, -0.3907,  0.8548, -0.4736,\n           0.3261, -0.4955,  0.8987,  0.6830,  0.3870, -0.6213,  0.5105,  0.3291,\n           0.7046, -0.4227,  0.5148,  0.2049, -0.0371, -0.3230,  0.1148,  0.0255,\n           0.4231,  0.4875,  0.1542, -0.5588, -0.6301, -0.3530, -0.1522,  0.2129,\n           0.3040,  0.6377,  0.0215,  0.7393, -0.6394, -0.8165,  0.4022,  0.4165,\n           0.2103,  0.3770,  0.8545,  0.6022, -0.3440,  0.2846, -0.3118,  0.0881,\n           0.3674,  0.2813,  0.3106, -0.2004, -0.3030,  0.4171,  0.2489, -0.3596],\n         [ 0.0261, -0.1333,  0.1908, -0.1756, -0.3809, -0.0554,  0.2939,  0.1332,\n          -0.3087,  0.5698,  0.3379, -0.6523, -0.3324, -0.3277, -0.5045,  0.6272,\n          -0.3907,  0.9257,  0.0798,  0.8016,  0.4776,  0.6829,  0.4164,  0.2984,\n           0.5200,  0.5470,  0.5529,  0.4053,  0.7464,  0.1074, -0.5330,  0.5100,\n          -0.5433,  0.3861,  0.4945, -0.0649, -0.0115,  0.1412, -0.6838, -0.5946,\n           0.0146, -0.5170, -0.1392,  0.3127, -0.5835,  0.0457,  0.4283, -0.6073,\n          -0.5707,  0.0537,  0.2650,  0.6162,  0.2140,  0.3538,  0.1556, -0.5076,\n           0.0034,  0.0918,  0.6240,  0.5439, -0.2919,  0.5184, -0.0154,  0.3336],\n         [-0.3862, -0.4900, -0.0569, -0.4751, -0.6093, -0.4442,  0.0105,  0.0188,\n           0.2726, -0.2539, -0.1220, -0.0047,  0.4079,  0.7508, -0.1025,  0.0772,\n           0.4928,  0.7766,  0.0036, -0.5925, -0.0245, -0.1214, -0.7657, -0.3321,\n           0.4042,  0.7418,  0.3267, -0.9169,  0.0541, -0.2212,  0.4216,  0.5732,\n          -0.0106, -0.0916,  0.2855, -0.5213, -0.3974,  0.1453, -0.7759,  0.6591,\n           0.2218,  0.3221,  0.7089, -0.1309,  0.2191, -0.6971, -0.4146, -0.4701,\n           0.7974,  0.6102,  0.3273,  0.7465,  0.5919,  0.5586, -0.0208,  0.2418,\n           0.8133,  0.2733,  0.1990, -0.3475, -0.8236,  0.5686, -0.3791, -0.2711],\n         [-0.2242,  0.4847,  0.3000, -0.0451, -0.6858, -0.1867,  0.4379,  0.6991,\n          -0.8945, -0.6838,  0.4854, -0.6396, -0.3962,  0.7978, -0.2584,  0.4777,\n          -0.2203,  0.8945, -0.5786,  0.1160,  0.8332,  0.4655, -0.2211,  0.3726,\n           0.3544,  0.4703,  0.2646, -0.4170, -0.6740,  0.4321, -0.5403,  0.5869,\n          -0.5015, -0.1723,  0.1108,  0.4609, -0.2783, -0.4636,  0.0501,  0.0106,\n           0.2123,  0.2226, -0.0271,  0.8307,  0.6428, -0.7588,  0.5831, -0.3588,\n           0.1688,  0.8412, -0.6518, -0.3424, -0.4633,  0.8793, -0.1686,  0.6032,\n          -0.1395,  0.8624, -0.1018,  0.1862,  0.3607,  0.8819, -0.4049,  0.0637],\n         [ 0.4593, -0.0051, -0.0462, -0.1433,  0.1694,  0.1038, -0.7115,  0.0801,\n          -0.3300,  0.5956,  0.3534, -0.0353,  0.6125,  0.0278,  0.1116,  0.6838,\n           0.7400,  0.0339,  0.0758, -0.5823,  0.7779, -0.2324,  0.0558,  0.7275,\n           0.3275, -0.3459, -0.0960, -0.4568, -0.3723, -0.6015, -0.1779,  0.6861,\n          -0.8925, -0.0227, -0.3522, -0.1623,  0.5621, -0.0978, -0.8623,  0.0046,\n          -0.2413, -0.5191,  0.6144,  0.2575, -0.0555, -0.0693, -0.2063, -0.6549,\n           0.0163,  0.6204,  0.3354,  0.7789,  0.2686,  0.0029,  0.0053,  0.3055,\n           0.2103,  0.6792,  0.2188, -0.1951, -0.7509,  0.1462,  0.2514, -0.4057],\n         [-0.0540,  0.5149,  0.2177,  0.0733, -0.6286, -0.0117,  0.4756,  0.5430,\n          -0.5006,  0.2825, -0.0886, -0.2457, -0.5953, -0.0663, -0.1716,  0.7941,\n          -0.6467,  0.8621, -0.1112,  0.8020,  0.1037,  0.4106,  0.5163,  0.3270,\n          -0.1902,  0.6443,  0.1778,  0.0821,  0.2980,  0.0158, -0.1086,  0.5598,\n          -0.6695,  0.3231,  0.3864,  0.1774,  0.6229, -0.2911, -0.6918, -0.6462,\n           0.2549, -0.1236,  0.1051,  0.2557, -0.3720, -0.1041, -0.1377, -0.4493,\n           0.0222,  0.1832,  0.3550,  0.4043,  0.2245,  0.1590,  0.1605, -0.2994,\n          -0.3572, -0.3441,  0.6843,  0.5671, -0.2131, -0.0855, -0.4978,  0.3798],\n         [-0.6129, -0.5666,  0.7204, -0.0935,  0.1004, -0.0161,  0.1938,  0.1707,\n          -0.4825,  0.7842,  0.3232, -0.0848, -0.1028,  0.5755,  0.4247,  0.2018,\n           0.7310, -0.6788,  0.0262,  0.8549,  0.3366, -0.4332, -0.5739,  0.0593,\n           0.3168, -0.0672, -0.5948, -0.1587, -0.2607,  0.2047,  0.2149,  0.1248,\n           0.2473,  0.2404, -0.3752,  0.2089, -0.0070, -0.3415,  0.2565, -0.3274,\n          -0.6238,  0.3469, -0.2644,  0.4302,  0.3200,  0.0302,  0.1549,  0.5087,\n           0.7130,  0.6576, -0.0634, -0.6334, -0.2961,  0.6471,  0.6239,  0.5818,\n           0.2858,  0.1579, -0.0696, -0.3874, -0.5129,  0.2314,  0.2167, -0.1859],\n         [-0.3034, -0.5160, -0.2045, -0.8402,  0.7579,  0.0772, -0.6557, -0.2713,\n           0.0483,  0.2883,  0.2842, -0.2808,  0.1182, -0.2878,  0.1416, -0.8131,\n           0.7248, -0.7479,  0.6531, -0.1562, -0.6657,  0.5062, -0.3834,  0.7393,\n          -0.6115, -0.5548,  0.1293,  0.7187, -0.8316,  0.5431, -0.3831, -0.5027,\n          -0.3177,  0.0965, -0.5309,  0.0849,  0.3113, -0.3324,  0.9437,  0.0462,\n          -0.1140,  0.7515, -0.7265,  0.3265,  0.4789,  0.0845, -0.5812,  0.2474,\n           0.0346, -0.0660,  0.0970, -0.4096, -0.5952, -0.0939, -0.1458, -0.8204,\n           0.2580, -0.0789, -0.1157, -0.4085, -0.5181,  0.3242,  0.0118, -0.3160]],\n        grad_fn=<SqueezeBackward1>),\n tensor([[-0.3034, -0.5160, -0.2045, -0.8402,  0.7579,  0.0772, -0.6557, -0.2713,\n           0.0483,  0.2883,  0.2842, -0.2808,  0.1182, -0.2878,  0.1416, -0.8131,\n           0.7248, -0.7479,  0.6531, -0.1562, -0.6657,  0.5062, -0.3834,  0.7393,\n          -0.6115, -0.5548,  0.1293,  0.7187, -0.8316,  0.5431, -0.3831, -0.5027,\n          -0.3177,  0.0965, -0.5309,  0.0849,  0.3113, -0.3324,  0.9437,  0.0462,\n          -0.1140,  0.7515, -0.7265,  0.3265,  0.4789,  0.0845, -0.5812,  0.2474,\n           0.0346, -0.0660,  0.0970, -0.4096, -0.5952, -0.0939, -0.1458, -0.8204,\n           0.2580, -0.0789, -0.1157, -0.4085, -0.5181,  0.3242,  0.0118, -0.3160]],\n        grad_fn=<SqueezeBackward1>))"},"metadata":{}}],"execution_count":299},{"cell_type":"code","source":"\nlen(y(a))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:26.074435Z","iopub.execute_input":"2026-01-04T12:39:26.074735Z","iopub.status.idle":"2026-01-04T12:39:26.081542Z","shell.execute_reply.started":"2026-01-04T12:39:26.074712Z","shell.execute_reply":"2026-01-04T12:39:26.080629Z"}},"outputs":[{"execution_count":300,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}],"execution_count":300},{"cell_type":"markdown","source":"**What and Why**\n\n- Here for one tupple for the o1, o2, o3 ...\n- and another triple for the final output\n- So we can't use the rRNNduring the sequential module\n- because the module expert ,the output  is given to another layer input","metadata":{}},{"cell_type":"code","source":"# hidden output of the RNN\ny(a)[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:26.114280Z","iopub.execute_input":"2026-01-04T12:39:26.114625Z","iopub.status.idle":"2026-01-04T12:39:26.125668Z","shell.execute_reply.started":"2026-01-04T12:39:26.114596Z","shell.execute_reply":"2026-01-04T12:39:26.124775Z"}},"outputs":[{"execution_count":301,"output_type":"execute_result","data":{"text/plain":"tensor([[-0.2486, -0.4983, -0.1773, -0.1265,  0.1133,  0.6968,  0.7148, -0.1298,\n         -0.1708, -0.4045,  0.4692, -0.1653, -0.3188,  0.5821,  0.0809,  0.0675,\n         -0.2989,  0.1629,  0.2005, -0.1664,  0.7893, -0.1634, -0.3210, -0.2256,\n         -0.8517,  0.1115, -0.1994, -0.1522, -0.5058,  0.6796,  0.2720, -0.2281,\n         -0.6166,  0.1463, -0.5640,  0.5867, -0.0148,  0.1488,  0.4264,  0.0836,\n         -0.1851,  0.2303, -0.1853,  0.0345, -0.5174, -0.1076,  0.0730,  0.2008,\n          0.3194, -0.2464,  0.1246, -0.1831,  0.4843,  0.1261,  0.3453, -0.3822,\n         -0.3025,  0.0804, -0.0257, -0.2708,  0.1592,  0.2884,  0.1749, -0.2183],\n        [-0.3591,  0.4443,  0.3611, -0.4099, -0.0385, -0.1709, -0.0205, -0.8223,\n         -0.7038, -0.8054,  0.6134, -0.4221,  0.0130, -0.3907,  0.8548, -0.4736,\n          0.3261, -0.4955,  0.8987,  0.6830,  0.3870, -0.6213,  0.5105,  0.3291,\n          0.7046, -0.4227,  0.5148,  0.2049, -0.0371, -0.3230,  0.1148,  0.0255,\n          0.4231,  0.4875,  0.1542, -0.5588, -0.6301, -0.3530, -0.1522,  0.2129,\n          0.3040,  0.6377,  0.0215,  0.7393, -0.6394, -0.8165,  0.4022,  0.4165,\n          0.2103,  0.3770,  0.8545,  0.6022, -0.3440,  0.2846, -0.3118,  0.0881,\n          0.3674,  0.2813,  0.3106, -0.2004, -0.3030,  0.4171,  0.2489, -0.3596],\n        [ 0.0261, -0.1333,  0.1908, -0.1756, -0.3809, -0.0554,  0.2939,  0.1332,\n         -0.3087,  0.5698,  0.3379, -0.6523, -0.3324, -0.3277, -0.5045,  0.6272,\n         -0.3907,  0.9257,  0.0798,  0.8016,  0.4776,  0.6829,  0.4164,  0.2984,\n          0.5200,  0.5470,  0.5529,  0.4053,  0.7464,  0.1074, -0.5330,  0.5100,\n         -0.5433,  0.3861,  0.4945, -0.0649, -0.0115,  0.1412, -0.6838, -0.5946,\n          0.0146, -0.5170, -0.1392,  0.3127, -0.5835,  0.0457,  0.4283, -0.6073,\n         -0.5707,  0.0537,  0.2650,  0.6162,  0.2140,  0.3538,  0.1556, -0.5076,\n          0.0034,  0.0918,  0.6240,  0.5439, -0.2919,  0.5184, -0.0154,  0.3336],\n        [-0.3862, -0.4900, -0.0569, -0.4751, -0.6093, -0.4442,  0.0105,  0.0188,\n          0.2726, -0.2539, -0.1220, -0.0047,  0.4079,  0.7508, -0.1025,  0.0772,\n          0.4928,  0.7766,  0.0036, -0.5925, -0.0245, -0.1214, -0.7657, -0.3321,\n          0.4042,  0.7418,  0.3267, -0.9169,  0.0541, -0.2212,  0.4216,  0.5732,\n         -0.0106, -0.0916,  0.2855, -0.5213, -0.3974,  0.1453, -0.7759,  0.6591,\n          0.2218,  0.3221,  0.7089, -0.1309,  0.2191, -0.6971, -0.4146, -0.4701,\n          0.7974,  0.6102,  0.3273,  0.7465,  0.5919,  0.5586, -0.0208,  0.2418,\n          0.8133,  0.2733,  0.1990, -0.3475, -0.8236,  0.5686, -0.3791, -0.2711],\n        [-0.2242,  0.4847,  0.3000, -0.0451, -0.6858, -0.1867,  0.4379,  0.6991,\n         -0.8945, -0.6838,  0.4854, -0.6396, -0.3962,  0.7978, -0.2584,  0.4777,\n         -0.2203,  0.8945, -0.5786,  0.1160,  0.8332,  0.4655, -0.2211,  0.3726,\n          0.3544,  0.4703,  0.2646, -0.4170, -0.6740,  0.4321, -0.5403,  0.5869,\n         -0.5015, -0.1723,  0.1108,  0.4609, -0.2783, -0.4636,  0.0501,  0.0106,\n          0.2123,  0.2226, -0.0271,  0.8307,  0.6428, -0.7588,  0.5831, -0.3588,\n          0.1688,  0.8412, -0.6518, -0.3424, -0.4633,  0.8793, -0.1686,  0.6032,\n         -0.1395,  0.8624, -0.1018,  0.1862,  0.3607,  0.8819, -0.4049,  0.0637],\n        [ 0.4593, -0.0051, -0.0462, -0.1433,  0.1694,  0.1038, -0.7115,  0.0801,\n         -0.3300,  0.5956,  0.3534, -0.0353,  0.6125,  0.0278,  0.1116,  0.6838,\n          0.7400,  0.0339,  0.0758, -0.5823,  0.7779, -0.2324,  0.0558,  0.7275,\n          0.3275, -0.3459, -0.0960, -0.4568, -0.3723, -0.6015, -0.1779,  0.6861,\n         -0.8925, -0.0227, -0.3522, -0.1623,  0.5621, -0.0978, -0.8623,  0.0046,\n         -0.2413, -0.5191,  0.6144,  0.2575, -0.0555, -0.0693, -0.2063, -0.6549,\n          0.0163,  0.6204,  0.3354,  0.7789,  0.2686,  0.0029,  0.0053,  0.3055,\n          0.2103,  0.6792,  0.2188, -0.1951, -0.7509,  0.1462,  0.2514, -0.4057],\n        [-0.0540,  0.5149,  0.2177,  0.0733, -0.6286, -0.0117,  0.4756,  0.5430,\n         -0.5006,  0.2825, -0.0886, -0.2457, -0.5953, -0.0663, -0.1716,  0.7941,\n         -0.6467,  0.8621, -0.1112,  0.8020,  0.1037,  0.4106,  0.5163,  0.3270,\n         -0.1902,  0.6443,  0.1778,  0.0821,  0.2980,  0.0158, -0.1086,  0.5598,\n         -0.6695,  0.3231,  0.3864,  0.1774,  0.6229, -0.2911, -0.6918, -0.6462,\n          0.2549, -0.1236,  0.1051,  0.2557, -0.3720, -0.1041, -0.1377, -0.4493,\n          0.0222,  0.1832,  0.3550,  0.4043,  0.2245,  0.1590,  0.1605, -0.2994,\n         -0.3572, -0.3441,  0.6843,  0.5671, -0.2131, -0.0855, -0.4978,  0.3798],\n        [-0.6129, -0.5666,  0.7204, -0.0935,  0.1004, -0.0161,  0.1938,  0.1707,\n         -0.4825,  0.7842,  0.3232, -0.0848, -0.1028,  0.5755,  0.4247,  0.2018,\n          0.7310, -0.6788,  0.0262,  0.8549,  0.3366, -0.4332, -0.5739,  0.0593,\n          0.3168, -0.0672, -0.5948, -0.1587, -0.2607,  0.2047,  0.2149,  0.1248,\n          0.2473,  0.2404, -0.3752,  0.2089, -0.0070, -0.3415,  0.2565, -0.3274,\n         -0.6238,  0.3469, -0.2644,  0.4302,  0.3200,  0.0302,  0.1549,  0.5087,\n          0.7130,  0.6576, -0.0634, -0.6334, -0.2961,  0.6471,  0.6239,  0.5818,\n          0.2858,  0.1579, -0.0696, -0.3874, -0.5129,  0.2314,  0.2167, -0.1859],\n        [-0.3034, -0.5160, -0.2045, -0.8402,  0.7579,  0.0772, -0.6557, -0.2713,\n          0.0483,  0.2883,  0.2842, -0.2808,  0.1182, -0.2878,  0.1416, -0.8131,\n          0.7248, -0.7479,  0.6531, -0.1562, -0.6657,  0.5062, -0.3834,  0.7393,\n         -0.6115, -0.5548,  0.1293,  0.7187, -0.8316,  0.5431, -0.3831, -0.5027,\n         -0.3177,  0.0965, -0.5309,  0.0849,  0.3113, -0.3324,  0.9437,  0.0462,\n         -0.1140,  0.7515, -0.7265,  0.3265,  0.4789,  0.0845, -0.5812,  0.2474,\n          0.0346, -0.0660,  0.0970, -0.4096, -0.5952, -0.0939, -0.1458, -0.8204,\n          0.2580, -0.0789, -0.1157, -0.4085, -0.5181,  0.3242,  0.0118, -0.3160]],\n       grad_fn=<SqueezeBackward1>)"},"metadata":{}}],"execution_count":301},{"cell_type":"code","source":"len(y(a))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:26.164091Z","iopub.execute_input":"2026-01-04T12:39:26.164849Z","iopub.status.idle":"2026-01-04T12:39:26.170872Z","shell.execute_reply.started":"2026-01-04T12:39:26.164814Z","shell.execute_reply":"2026-01-04T12:39:26.170038Z"}},"outputs":[{"execution_count":302,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}],"execution_count":302},{"cell_type":"code","source":"# Output of the RNN \ny(a)[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:26.204590Z","iopub.execute_input":"2026-01-04T12:39:26.205784Z","iopub.status.idle":"2026-01-04T12:39:26.213337Z","shell.execute_reply.started":"2026-01-04T12:39:26.205744Z","shell.execute_reply":"2026-01-04T12:39:26.212568Z"}},"outputs":[{"execution_count":303,"output_type":"execute_result","data":{"text/plain":"tensor([[-0.3034, -0.5160, -0.2045, -0.8402,  0.7579,  0.0772, -0.6557, -0.2713,\n          0.0483,  0.2883,  0.2842, -0.2808,  0.1182, -0.2878,  0.1416, -0.8131,\n          0.7248, -0.7479,  0.6531, -0.1562, -0.6657,  0.5062, -0.3834,  0.7393,\n         -0.6115, -0.5548,  0.1293,  0.7187, -0.8316,  0.5431, -0.3831, -0.5027,\n         -0.3177,  0.0965, -0.5309,  0.0849,  0.3113, -0.3324,  0.9437,  0.0462,\n         -0.1140,  0.7515, -0.7265,  0.3265,  0.4789,  0.0845, -0.5812,  0.2474,\n          0.0346, -0.0660,  0.0970, -0.4096, -0.5952, -0.0939, -0.1458, -0.8204,\n          0.2580, -0.0789, -0.1157, -0.4085, -0.5181,  0.3242,  0.0118, -0.3160]],\n       grad_fn=<SqueezeBackward1>)"},"metadata":{}}],"execution_count":303},{"cell_type":"code","source":"# final output of the rnn\ny(a)[1].shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:26.249245Z","iopub.execute_input":"2026-01-04T12:39:26.249596Z","iopub.status.idle":"2026-01-04T12:39:26.256229Z","shell.execute_reply.started":"2026-01-04T12:39:26.249573Z","shell.execute_reply":"2026-01-04T12:39:26.255347Z"}},"outputs":[{"execution_count":304,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 64])"},"metadata":{}}],"execution_count":304},{"cell_type":"markdown","source":"## Output Layer","metadata":{}},{"cell_type":"code","source":"# final output\nb = y(a)[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:26.284612Z","iopub.execute_input":"2026-01-04T12:39:26.284923Z","iopub.status.idle":"2026-01-04T12:39:26.289967Z","shell.execute_reply.started":"2026-01-04T12:39:26.284900Z","shell.execute_reply":"2026-01-04T12:39:26.288809Z"}},"outputs":[],"execution_count":305},{"cell_type":"code","source":"# send to the linear \n# 64 input form RNN and 324 output\nz = nn.Linear(64, 324)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:26.320991Z","iopub.execute_input":"2026-01-04T12:39:26.321645Z","iopub.status.idle":"2026-01-04T12:39:26.326008Z","shell.execute_reply.started":"2026-01-04T12:39:26.321616Z","shell.execute_reply":"2026-01-04T12:39:26.325160Z"}},"outputs":[],"execution_count":306},{"cell_type":"code","source":"z(b)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:26.343654Z","iopub.execute_input":"2026-01-04T12:39:26.344463Z","iopub.status.idle":"2026-01-04T12:39:26.353655Z","shell.execute_reply.started":"2026-01-04T12:39:26.344429Z","shell.execute_reply":"2026-01-04T12:39:26.352614Z"}},"outputs":[{"execution_count":307,"output_type":"execute_result","data":{"text/plain":"tensor([[-3.8864e-02,  9.2004e-02, -5.9362e-02, -7.2805e-03, -5.4006e-01,\n         -8.9106e-02,  2.0007e-01,  2.3395e-01, -3.4819e-01,  1.0696e-01,\n          4.3824e-01,  3.0460e-02, -5.3667e-01, -1.8324e-01,  1.1028e-01,\n          2.9386e-01,  5.7324e-01,  3.1396e-01, -3.4214e-02, -2.7798e-01,\n         -4.5682e-01, -1.2937e-01,  3.2449e-03, -4.5834e-01,  6.3422e-02,\n          5.8191e-01,  3.3166e-01,  2.9784e-01,  7.0271e-01, -3.4590e-01,\n          2.8458e-01, -7.7505e-02,  7.1869e-02, -1.4535e-01,  3.2216e-01,\n          7.3568e-01, -1.4576e-01,  9.3595e-02, -1.3700e-01,  2.4875e-01,\n          3.6027e-01,  1.1423e-01,  2.6750e-01,  2.1785e-01, -2.3492e-01,\n         -4.6785e-01, -3.7714e-01, -6.2081e-01,  5.5224e-01,  1.5887e-01,\n          8.3219e-01,  2.6210e-02,  2.2872e-01, -5.0000e-03,  1.5053e-01,\n         -4.0717e-02,  1.1372e-01,  1.9209e-01,  4.1949e-01,  2.1791e-01,\n         -1.4416e-01, -3.3569e-01,  2.6504e-01,  4.9893e-01,  5.0909e-01,\n         -2.0499e-02, -6.0669e-02, -1.4363e-01, -4.0725e-01,  3.4674e-01,\n          2.0749e-02,  4.1613e-01,  5.2346e-02,  4.6633e-01,  2.9548e-02,\n         -1.3006e-01, -1.5364e-01, -2.1490e-01,  5.3088e-02, -1.6959e-01,\n          3.1600e-01, -1.3514e-01, -2.9086e-01,  3.9162e-01, -2.5886e-01,\n         -3.6683e-02,  2.5801e-01, -2.7086e-01, -1.0420e-02, -1.0859e-01,\n         -1.6010e-01, -1.5602e-01,  4.7022e-01,  4.4745e-01, -5.3828e-03,\n          5.1674e-02,  1.5994e-01, -1.2247e-01,  1.1643e-01,  1.4192e-01,\n          1.9031e-01, -1.4191e-01,  1.3606e-01, -1.4040e-01,  1.4237e-01,\n         -7.0549e-02,  3.3026e-01, -2.9261e-01, -5.3713e-01, -2.6135e-01,\n         -9.4283e-02,  1.2395e-01, -3.4847e-01,  1.3949e-01,  4.3726e-01,\n         -1.3447e-01, -2.2636e-01, -4.2958e-01,  3.6318e-01, -3.9254e-01,\n         -1.5768e-01, -1.8690e-01,  5.4742e-02, -2.8624e-02,  3.6156e-01,\n          3.5383e-02,  1.7553e-01,  7.2810e-02,  1.0130e-01,  7.9226e-02,\n          1.6662e-01, -4.1700e-01, -1.5454e-01,  1.2003e-01, -4.7786e-01,\n          1.3868e-01,  4.2044e-01, -4.9284e-02,  4.4747e-01,  2.5722e-01,\n         -2.9759e-01,  5.6199e-01, -4.7048e-01, -1.8875e-01,  1.3504e-01,\n         -2.1869e-01,  8.7717e-02,  5.8796e-02,  6.0049e-01, -3.3575e-02,\n         -3.3165e-01, -4.8190e-01, -4.2438e-01, -6.9992e-02,  4.7638e-02,\n         -1.1103e-01, -1.7807e-01, -2.8013e-02,  4.0970e-01, -3.3791e-02,\n         -4.9348e-01, -2.5690e-01, -4.9651e-04,  3.0445e-01,  4.0320e-01,\n          2.4628e-01, -2.7946e-01, -2.3945e-01,  2.7844e-01,  3.6429e-01,\n         -2.6663e-01, -1.5552e-01,  4.4339e-01,  2.3350e-01,  6.3054e-01,\n          2.0599e-01,  5.3258e-01, -1.0367e-01, -1.9020e-01, -2.7149e-01,\n          2.2644e-01, -1.4582e-01, -4.1265e-01,  2.0857e-01, -2.0905e-01,\n          3.1322e-01, -5.6873e-02, -1.5707e-02, -4.9230e-01,  4.7300e-02,\n          4.6259e-02, -7.1662e-01, -2.6553e-01, -1.1996e-01,  1.4869e-01,\n         -2.9174e-01,  8.9760e-02, -1.7088e-01, -3.9188e-01, -6.3526e-01,\n          1.8758e-01, -2.7236e-01,  4.4027e-01,  4.5032e-01,  8.0242e-03,\n         -5.9672e-02,  2.9724e-01, -7.3631e-04,  3.4404e-01,  9.5297e-02,\n         -2.4993e-01, -3.7674e-01,  7.5062e-03, -8.8413e-02, -9.2763e-02,\n         -3.0219e-02,  3.9634e-01, -8.2880e-02,  3.0823e-01,  2.7133e-01,\n         -1.4352e-01,  8.5489e-02,  2.5596e-01,  1.1815e-01, -3.0861e-01,\n          1.7431e-01,  2.1885e-01,  3.1391e-01, -2.4467e-01,  9.5267e-02,\n         -3.7583e-01,  1.8277e-01,  4.4737e-01,  2.4608e-01,  8.0733e-01,\n         -2.5240e-01,  6.0187e-02,  1.9717e-01, -1.2393e-01,  2.8024e-01,\n         -5.6681e-01, -5.1883e-02, -1.4783e-01, -1.3010e-01,  2.0184e-01,\n         -1.3072e-02,  2.7913e-01, -2.1691e-01, -1.8129e-01, -1.9693e-01,\n         -3.1180e-01, -1.6743e-01, -3.5858e-01,  4.9332e-01, -2.5435e-02,\n          1.7349e-01,  3.2574e-01, -1.7085e-01,  8.3081e-02,  4.6545e-02,\n         -5.0098e-01, -1.0370e-02,  1.5722e-01,  3.1290e-01,  4.2712e-01,\n         -3.3231e-01,  4.6150e-01, -1.9962e-01, -4.5418e-01, -1.8973e-01,\n         -2.6239e-01, -3.1441e-02, -2.1155e-01, -1.6567e-01,  4.1998e-01,\n          3.7740e-02, -5.8290e-01, -4.2226e-01,  2.5060e-01,  2.6469e-02,\n          1.0973e-01, -3.0834e-01,  3.4587e-02,  9.8280e-02,  2.0980e-01,\n          6.6613e-01, -1.3615e-01,  3.9578e-01, -1.5202e-01, -2.1076e-01,\n         -3.4796e-01,  3.1523e-01, -2.2052e-01,  6.6053e-02,  6.8846e-02,\n          3.3403e-01, -3.2815e-01,  2.8904e-01, -1.5476e-01, -5.5141e-01,\n         -2.4129e-01,  1.2331e-01,  4.6792e-02,  1.9263e-01,  2.8216e-01,\n         -6.5464e-02, -2.6662e-01,  9.3316e-02,  1.8713e-01,  2.3352e-01,\n         -7.7635e-02,  2.4201e-01, -4.9295e-01,  5.4725e-01,  2.6504e-01,\n          1.1387e-02, -3.6733e-01,  2.5787e-01, -4.3695e-01, -7.6713e-03,\n          1.1157e-02, -2.0122e-01, -2.6083e-02, -5.4702e-02]],\n       grad_fn=<AddmmBackward0>)"},"metadata":{}}],"execution_count":307},{"cell_type":"code","source":"# for each vocabulary word we have probability \nz(b).shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:26.379463Z","iopub.execute_input":"2026-01-04T12:39:26.380243Z","iopub.status.idle":"2026-01-04T12:39:26.385798Z","shell.execute_reply.started":"2026-01-04T12:39:26.380218Z","shell.execute_reply":"2026-01-04T12:39:26.385030Z"}},"outputs":[{"execution_count":308,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 324])"},"metadata":{}}],"execution_count":308},{"cell_type":"markdown","source":"- That means we need to write the manual forward function","metadata":{}},{"cell_type":"markdown","source":"## Debugging the size ","metadata":{}},{"cell_type":"code","source":"x = nn.Embedding(324, embedding_dim=50)\ny = nn.RNN(50, 64)\nz = nn.Linear(64, 324)\n\n# input value shape\na = dataset[0][0].reshape(1, 6)\nprint(a.shape)\n\n# embedding shape\nb = x(a)\nprint(b.shape)\n\n# hidden, output of the rnn layer\nc, d = y(b)\nprint(c.shape)\nprint(d.shape)\n\n# output layer shape\ne = z(d)\nprint(e.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:26.413849Z","iopub.execute_input":"2026-01-04T12:39:26.414694Z","iopub.status.idle":"2026-01-04T12:39:26.423602Z","shell.execute_reply.started":"2026-01-04T12:39:26.414667Z","shell.execute_reply":"2026-01-04T12:39:26.422812Z"}},"outputs":[{"name":"stdout","text":"torch.Size([1, 6])\ntorch.Size([1, 6, 50])\ntorch.Size([1, 6, 64])\ntorch.Size([1, 6, 64])\ntorch.Size([1, 6, 324])\n","output_type":"stream"}],"execution_count":309},{"cell_type":"markdown","source":"**1st impovement**\n\n- By adding this parameter\n- `batch_first=Ture`\n- Notice the d and e\n\n\n**2nd Impovement**\n- squeeze the first 1 value\n- so the shape would be 1, 324 always\n- despite all the changing question sizes","metadata":{}},{"cell_type":"code","source":"x = nn.Embedding(324, embedding_dim=50)\ny = nn.RNN(50, 64, batch_first=True)\nz = nn.Linear(64, 324)\n\n# input value shape\na = dataset[0][0].reshape(1, 6)\nprint(a.shape)\n\n# embedding shape\nb = x(a)\nprint(b.shape)\n\n# hidden, output of the rnn layer\nc, d = y(b)\nprint(c.shape)\nprint(d.shape)\n\n# output layer shape\ne = z(d.squeeze(0))\nprint(e.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:26.454419Z","iopub.execute_input":"2026-01-04T12:39:26.454703Z","iopub.status.idle":"2026-01-04T12:39:26.464471Z","shell.execute_reply.started":"2026-01-04T12:39:26.454683Z","shell.execute_reply":"2026-01-04T12:39:26.463613Z"}},"outputs":[{"name":"stdout","text":"torch.Size([1, 6])\ntorch.Size([1, 6, 50])\ntorch.Size([1, 6, 64])\ntorch.Size([1, 1, 64])\ntorch.Size([1, 324])\n","output_type":"stream"}],"execution_count":310},{"cell_type":"markdown","source":"# Imp Parameter","metadata":{}},{"cell_type":"code","source":"LR = 0.001\nEPOCHS = 20","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:26.473247Z","iopub.execute_input":"2026-01-04T12:39:26.473905Z","iopub.status.idle":"2026-01-04T12:39:26.479131Z","shell.execute_reply.started":"2026-01-04T12:39:26.473876Z","shell.execute_reply":"2026-01-04T12:39:26.478307Z"}},"outputs":[],"execution_count":311},{"cell_type":"markdown","source":"# Loss function & Optimizer","metadata":{}},{"cell_type":"code","source":"model = SimpleRNN(len(vocab))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:26.490732Z","iopub.execute_input":"2026-01-04T12:39:26.491032Z","iopub.status.idle":"2026-01-04T12:39:26.496710Z","shell.execute_reply.started":"2026-01-04T12:39:26.491008Z","shell.execute_reply":"2026-01-04T12:39:26.495797Z"}},"outputs":[],"execution_count":312},{"cell_type":"code","source":"summary(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:26.531051Z","iopub.execute_input":"2026-01-04T12:39:26.531661Z","iopub.status.idle":"2026-01-04T12:39:26.537377Z","shell.execute_reply.started":"2026-01-04T12:39:26.531633Z","shell.execute_reply":"2026-01-04T12:39:26.536556Z"}},"outputs":[{"execution_count":313,"output_type":"execute_result","data":{"text/plain":"=================================================================\nLayer (type:depth-idx)                   Param #\n=================================================================\nSimpleRNN                                --\n‚îú‚îÄEmbedding: 1-1                         16,300\n‚îú‚îÄRNN: 1-2                               7,424\n‚îú‚îÄLinear: 1-3                            21,190\n=================================================================\nTotal params: 44,914\nTrainable params: 44,914\nNon-trainable params: 0\n================================================================="},"metadata":{}}],"execution_count":313},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=LR)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:26.539859Z","iopub.execute_input":"2026-01-04T12:39:26.540304Z","iopub.status.idle":"2026-01-04T12:39:26.554381Z","shell.execute_reply.started":"2026-01-04T12:39:26.540281Z","shell.execute_reply":"2026-01-04T12:39:26.553445Z"}},"outputs":[],"execution_count":314},{"cell_type":"markdown","source":"# Training Loop","metadata":{}},{"cell_type":"code","source":"for epoch in range(EPOCHS):\n    total_loss = 0\n\n    for q, ans in dataloader:\n        \n        optimizer.zero_grad()\n        output = model(q)\n        \n        loss = criterion(output, ans[0])\n        loss.backward()\n        optimizer.step()\n        \n        total_loss = total_loss + loss.sum().item()\n\n    print(f\" {epoch + 1} | Total Loss: {total_loss:.4f} \")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:26.571482Z","iopub.execute_input":"2026-01-04T12:39:26.571809Z","iopub.status.idle":"2026-01-04T12:39:31.066468Z","shell.execute_reply.started":"2026-01-04T12:39:26.571786Z","shell.execute_reply":"2026-01-04T12:39:31.065504Z"}},"outputs":[{"name":"stdout","text":" 1 | Total Loss: 526.3420 \n 2 | Total Loss: 460.3975 \n 3 | Total Loss: 381.1847 \n 4 | Total Loss: 317.0698 \n 5 | Total Loss: 266.1316 \n 6 | Total Loss: 218.1204 \n 7 | Total Loss: 174.2367 \n 8 | Total Loss: 136.6992 \n 9 | Total Loss: 105.3345 \n 10 | Total Loss: 80.9902 \n 11 | Total Loss: 62.4904 \n 12 | Total Loss: 49.1301 \n 13 | Total Loss: 39.1850 \n 14 | Total Loss: 31.3143 \n 15 | Total Loss: 25.8721 \n 16 | Total Loss: 21.2192 \n 17 | Total Loss: 17.7880 \n 18 | Total Loss: 14.9592 \n 19 | Total Loss: 13.0095 \n 20 | Total Loss: 11.1675 \n","output_type":"stream"}],"execution_count":315},{"cell_type":"markdown","source":"# Predict ","metadata":{}},{"cell_type":"code","source":"idx_to_word = {v: k for k, v in vocab.items()}\nidx_to_word","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:31.067836Z","iopub.execute_input":"2026-01-04T12:39:31.068773Z","iopub.status.idle":"2026-01-04T12:39:31.079782Z","shell.execute_reply.started":"2026-01-04T12:39:31.068748Z","shell.execute_reply":"2026-01-04T12:39:31.078933Z"}},"outputs":[{"execution_count":316,"output_type":"execute_result","data":{"text/plain":"{0: '<UNK>',\n 1: 'what',\n 2: 'is',\n 3: 'the',\n 4: 'capital',\n 5: 'of',\n 6: 'france',\n 7: 'paris',\n 8: 'germany',\n 9: 'berlin',\n 10: 'who',\n 11: 'wrote',\n 12: \"'to\",\n 13: 'kill',\n 14: 'a',\n 15: \"mockingbird'\",\n 16: 'harper-lee',\n 17: 'largest',\n 18: 'planet',\n 19: 'in',\n 20: 'our',\n 21: 'solar',\n 22: 'system',\n 23: 'jupiter',\n 24: 'boiling',\n 25: 'point',\n 26: 'water',\n 27: 'celsius',\n 28: '100',\n 29: 'painted',\n 30: 'mona',\n 31: 'lisa',\n 32: 'leonardo-da-vinci',\n 33: 'square',\n 34: 'root',\n 35: '64',\n 36: '8',\n 37: 'chemical',\n 38: 'symbol',\n 39: 'for',\n 40: 'gold',\n 41: 'au',\n 42: 'which',\n 43: 'year',\n 44: 'did',\n 45: 'world',\n 46: 'war',\n 47: 'ii',\n 48: 'end',\n 49: '1945',\n 50: 'longest',\n 51: 'river',\n 52: 'nile',\n 53: 'japan',\n 54: 'tokyo',\n 55: 'developed',\n 56: 'theory',\n 57: 'relativity',\n 58: 'albert-einstein',\n 59: 'freezing',\n 60: 'fahrenheit',\n 61: '32',\n 62: 'known',\n 63: 'as',\n 64: 'red',\n 65: 'mars',\n 66: 'author',\n 67: \"'1984'\",\n 68: 'george-orwell',\n 69: 'currency',\n 70: 'united',\n 71: 'kingdom',\n 72: 'pound',\n 73: 'india',\n 74: 'delhi',\n 75: 'discovered',\n 76: 'gravity',\n 77: 'newton',\n 78: 'how',\n 79: 'many',\n 80: 'continents',\n 81: 'are',\n 82: 'there',\n 83: 'on',\n 84: 'earth',\n 85: '7',\n 86: 'gas',\n 87: 'do',\n 88: 'plants',\n 89: 'use',\n 90: 'photosynthesis',\n 91: 'co2',\n 92: 'smallest',\n 93: 'prime',\n 94: 'number',\n 95: '2',\n 96: 'invented',\n 97: 'telephone',\n 98: 'alexander-graham-bell',\n 99: 'australia',\n 100: 'canberra',\n 101: 'ocean',\n 102: 'pacific-ocean',\n 103: 'speed',\n 104: 'light',\n 105: 'vacuum',\n 106: '299,792,458m/s',\n 107: 'language',\n 108: 'spoken',\n 109: 'brazil',\n 110: 'portuguese',\n 111: 'penicillin',\n 112: 'alexander-fleming',\n 113: 'canada',\n 114: 'ottawa',\n 115: 'mammal',\n 116: 'whale',\n 117: 'element',\n 118: 'has',\n 119: 'atomic',\n 120: '1',\n 121: 'hydrogen',\n 122: 'tallest',\n 123: 'mountain',\n 124: 'everest',\n 125: 'city',\n 126: 'big',\n 127: 'apple',\n 128: 'newyork',\n 129: 'planets',\n 130: \"'starry\",\n 131: \"night'\",\n 132: 'vangogh',\n 133: 'formula',\n 134: 'h2o',\n 135: 'italy',\n 136: 'rome',\n 137: 'country',\n 138: 'famous',\n 139: 'sushi',\n 140: 'was',\n 141: 'first',\n 142: 'person',\n 143: 'to',\n 144: 'step',\n 145: 'moon',\n 146: 'armstrong',\n 147: 'main',\n 148: 'ingredient',\n 149: 'guacamole',\n 150: 'avocado',\n 151: 'sides',\n 152: 'does',\n 153: 'hexagon',\n 154: 'have',\n 155: '6',\n 156: 'china',\n 157: 'yuan',\n 158: \"'pride\",\n 159: 'and',\n 160: \"prejudice'\",\n 161: 'jane-austen',\n 162: 'iron',\n 163: 'fe',\n 164: 'hardest',\n 165: 'natural',\n 166: 'substance',\n 167: 'diamond',\n 168: 'continent',\n 169: 'by',\n 170: 'area',\n 171: 'asia',\n 172: 'president',\n 173: 'states',\n 174: 'george-washington',\n 175: 'bird',\n 176: 'its',\n 177: 'ability',\n 178: 'mimic',\n 179: 'sounds',\n 180: 'parrot',\n 181: 'longest-running',\n 182: 'animated',\n 183: 'tv',\n 184: 'show',\n 185: 'simpsons',\n 186: 'vaticancity',\n 187: 'most',\n 188: 'moons',\n 189: 'saturn',\n 190: \"'romeo\",\n 191: \"juliet'\",\n 192: 'shakespeare',\n 193: \"earth's\",\n 194: 'atmosphere',\n 195: 'nitrogen',\n 196: 'bones',\n 197: 'adult',\n 198: 'human',\n 199: 'body',\n 200: '206',\n 201: 'metal',\n 202: 'liquid',\n 203: 'at',\n 204: 'room',\n 205: 'temperature',\n 206: 'mercury',\n 207: 'russia',\n 208: 'moscow',\n 209: 'electricity',\n 210: 'benjamin-franklin',\n 211: 'second-largest',\n 212: 'land',\n 213: 'color',\n 214: 'ripe',\n 215: 'banana',\n 216: 'yellow',\n 217: 'month',\n 218: '28',\n 219: 'days',\n 220: 'common',\n 221: 'february',\n 222: 'study',\n 223: 'living',\n 224: 'organisms',\n 225: 'called',\n 226: 'biology',\n 227: 'home',\n 228: 'great',\n 229: 'wall',\n 230: 'bees',\n 231: 'collect',\n 232: 'from',\n 233: 'flowers',\n 234: 'nectar',\n 235: 'opposite',\n 236: \"'day'\",\n 237: 'night',\n 238: 'south',\n 239: 'korea',\n 240: 'seoul',\n 241: 'bulb',\n 242: 'edison',\n 243: 'humans',\n 244: 'breathe',\n 245: 'survival',\n 246: 'oxygen',\n 247: '144',\n 248: '12',\n 249: 'pyramids',\n 250: 'giza',\n 251: 'egypt',\n 252: 'sea',\n 253: 'creature',\n 254: 'eight',\n 255: 'arms',\n 256: 'octopus',\n 257: 'holiday',\n 258: 'celebrated',\n 259: 'december',\n 260: '25',\n 261: 'christmas',\n 262: 'yen',\n 263: 'legs',\n 264: 'spider',\n 265: 'sport',\n 266: 'uses',\n 267: 'net,',\n 268: 'ball,',\n 269: 'hoop',\n 270: 'basketball',\n 271: 'kangaroos',\n 272: 'female',\n 273: 'minister',\n 274: 'uk',\n 275: 'margaretthatcher',\n 276: 'fastest',\n 277: 'animal',\n 278: 'cheetah',\n 279: 'periodic',\n 280: 'table',\n 281: 'spain',\n 282: 'madrid',\n 283: 'closest',\n 284: 'sun',\n 285: 'father',\n 286: 'computers',\n 287: 'charlesbabbage',\n 288: 'mexico',\n 289: 'mexicocity',\n 290: 'colors',\n 291: 'rainbow',\n 292: 'musical',\n 293: 'instrument',\n 294: 'black',\n 295: 'white',\n 296: 'keys',\n 297: 'piano',\n 298: 'americas',\n 299: '1492',\n 300: 'christophercolumbus',\n 301: 'disney',\n 302: 'character',\n 303: 'long',\n 304: 'nose',\n 305: 'grows',\n 306: 'it',\n 307: 'when',\n 308: 'lying',\n 309: 'pinocchio',\n 310: 'directed',\n 311: 'movie',\n 312: \"'titanic'\",\n 313: 'jamescameron',\n 314: 'superhero',\n 315: 'also',\n 316: 'dark',\n 317: 'knight',\n 318: 'batman',\n 319: 'brasilia',\n 320: 'fruit',\n 321: 'king',\n 322: 'fruits',\n 323: 'mango',\n 324: 'eiffel',\n 325: 'tower'}"},"metadata":{}}],"execution_count":316},{"cell_type":"code","source":"def predict(question, model, vocab, th=0.5):\n    \n    model.eval()\n\n    # Convert text ‚Üí indices\n    numerical_question = text_to_indices(question, vocab)\n    q_tensor = torch.tensor(numerical_question).unsqueeze(0)  # (1, seq_len)\n\n    with torch.no_grad():\n        output = model(q_tensor)   # (1, vocab_size)\n        probs = torch.softmax(output, dim=1)\n        value, idx = torch.max(probs, dim=1)\n\n    if value.item() < th:\n        print(\"Give me more data...\")\n        return\n\n    idx_to_word = {v: k for k, v in vocab.items()}\n\n    print(\"Answer is ..\")\n    print(idx_to_word[idx.item()])\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:31.080744Z","iopub.execute_input":"2026-01-04T12:39:31.081071Z","iopub.status.idle":"2026-01-04T12:39:31.095405Z","shell.execute_reply.started":"2026-01-04T12:39:31.081046Z","shell.execute_reply":"2026-01-04T12:39:31.094357Z"}},"outputs":[],"execution_count":317},{"cell_type":"code","source":"predict(\"What is the largest planet in our solar system?\", model, vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:31.097278Z","iopub.execute_input":"2026-01-04T12:39:31.097598Z","iopub.status.idle":"2026-01-04T12:39:31.115829Z","shell.execute_reply.started":"2026-01-04T12:39:31.097570Z","shell.execute_reply":"2026-01-04T12:39:31.114840Z"}},"outputs":[{"name":"stdout","text":"Answer is ..\njupiter\n","output_type":"stream"}],"execution_count":318},{"cell_type":"code","source":"predict(\"What is the boiling point of water in Celsius?\", model, vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:31.116773Z","iopub.execute_input":"2026-01-04T12:39:31.117034Z","iopub.status.idle":"2026-01-04T12:39:31.133501Z","shell.execute_reply.started":"2026-01-04T12:39:31.117007Z","shell.execute_reply":"2026-01-04T12:39:31.132657Z"}},"outputs":[{"name":"stdout","text":"Answer is ..\n100\n","output_type":"stream"}],"execution_count":319},{"cell_type":"code","source":"predict(\"What is the square root of 64?\", model, vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:31.134369Z","iopub.execute_input":"2026-01-04T12:39:31.134699Z","iopub.status.idle":"2026-01-04T12:39:31.150264Z","shell.execute_reply.started":"2026-01-04T12:39:31.134679Z","shell.execute_reply":"2026-01-04T12:39:31.149356Z"}},"outputs":[{"name":"stdout","text":"Answer is ..\n8\n","output_type":"stream"}],"execution_count":320},{"cell_type":"markdown","source":"#  What an ans üòÜ\n\n![](https://i.pinimg.com/736x/1e/98/8f/1e988f4c4d7df3c13df8a628e1ed6d5f.jpg)","metadata":{}},{"cell_type":"code","source":"predict(\"Who is rudra\", model, vocab)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-04T12:39:31.169370Z","iopub.execute_input":"2026-01-04T12:39:31.169682Z","iopub.status.idle":"2026-01-04T12:39:31.186458Z","shell.execute_reply.started":"2026-01-04T12:39:31.169653Z","shell.execute_reply":"2026-01-04T12:39:31.185547Z"}},"outputs":[{"name":"stdout","text":"Give me more data...\n","output_type":"stream"}],"execution_count":322},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}